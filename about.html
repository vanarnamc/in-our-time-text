<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>About Page</title>
    <link rel="stylesheet" href="./style.css">
    <link rel="icon" type="image/png" href="media/favicon.png">

    <style>
        body{
            background-color: white;
        }
    </style>
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
    <!-- Add any additional stylesheets or scripts here -->
</head>
<body>

    <!-- Link to Home Page -->
    <div>
        <a href="index.html" id="home" style="mix-blend-mode: difference;">inourti.me</a>
    </div>

    <!-- About Section -->
    <div class="about-section">
        <p>
            
            “We have now become aware of the possibility of arranging the entire human environment as a work of art, as a teaching machine designed to maximize perception and to make everyday learning a process of discovery. Application of this knowledge would be the equivalent of a thermostat controlling room temperature. It would seem only reasonable to extend such controls to all the sensory thresholds of our being.”
           <br><div>—Marshall McLuhan, The Medium is the Massage (1967)</div> 
        </p>
        <p> In a time where optimization, efficiency, and headlines dominate the collective consciousness, questions quickly arise. Does hyper-optimization come with diminishing, if not decreasing returns? How should we deliver the news, and what are the ethical concerns with the 24-hour news cyle? What does  it mean to live in a society where each moment, a new headline arises, many times, outdoing the previous one? Are there alternatives to click-bait journalism? 
            </p>
            Inourti.me employs facial recognition technology to monitor the user's eye movements using their computer's camera. Each time the user blinks, the system not only generates a new headline from the New York Times in real time, but also initiates a timer to measure the duration the user spends reading this headline. The time taken to read the headline influences the next interaction: the longer the reading time, the more intense and noisy the sound generated upon the user's subsequent blink. The use of consumer-grade equipment to track involuntary body movements, raises questions about vulnerability, privacy, hyperstimulation, and surveillance in our heavily media-influenced world.
            
        
    </div>
    <!-- <section id="demos"> -->

    <div id="liveView" class="videoView">
        <div style="position: fixed;">
          <video id="webcam" style="position: absolute; left: 0; top: 0; opacity: 0;" autoplay playsinline></video>
          <canvas id="output_canvas" width="1920" height="1080"></canvas>
          <div id="showHideText" style="position: fixed; bottom: 10px; right: 10px; z-index: 999999;">
            <span>Hide Diagram</span>
          </div>
        </div>
      </div>

      <div class="blend-shapes">
        <ul class="blend-shapes-list" id="video-blend-shapes"></ul>
      </div>
    </section>
  </div>
  
  <script type="module">
    let results = undefined;
    const videoBlendShapes = document.getElementById("video-blend-shapes");

    import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
    const { FaceLandmarker, FilesetResolver } = vision;
    let runningMode = "IMAGE";

    let faceLandmarker;
    const videoWidth = 1080;
    const dotColor = 'black'; // Initial color for dots
    let lastVideoTime = -1;

    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");

    document.addEventListener('DOMContentLoaded', async () => {
        await createFaceLandmarker();
        enableCam();
    });

    async function createFaceLandmarker() {
        const filesetResolver = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                delegate: "GPU"
            },
            outputFaceBlendshapes: true,
            runningMode: "VIDEO",
            numFaces: 1
        });
    }

    function enableCam() {
        const constraints = {
            video: {
                facingMode: "user"
            }
        };

        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
            video.srcObject = stream;
            video.addEventListener('loadeddata', predictWebcam);
        }).catch((error) => {
            console.error('Error accessing the webcam:', error);
        });
    }

    async function predictWebcam() {
    const aspectRatio = video.videoHeight / video.videoWidth;
    video.style.width = videoWidth + "px";
    video.style.height = videoWidth * aspectRatio + "px";

    // Adjust canvas size based on device pixel ratio for better resolution
    const pixelRatio = window.devicePixelRatio || 1;
    canvasElement.width = videoWidth * pixelRatio;
    canvasElement.height = (videoWidth * aspectRatio) * pixelRatio;
    canvasElement.style.width = videoWidth + "px";
    canvasElement.style.height = videoWidth * aspectRatio + "px";
    canvasCtx.scale(pixelRatio, pixelRatio);

    if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await faceLandmarker.setOptions({ runningMode: runningMode });
    }

    let startTimeMs = performance.now();
    if (lastVideoTime !== video.currentTime) {
        lastVideoTime = video.currentTime;
        results = await faceLandmarker.detectForVideo(video, startTimeMs);
    }

    if (results && results.faceLandmarks) {
        canvasCtx.save();
        canvasCtx.translate(canvasElement.width / pixelRatio, 0);
        canvasCtx.scale(-1, 1);

        const dotSize = 5; // Adjust dot size for visibility

        for (const landmarks of results.faceLandmarks) {
            canvasCtx.fillStyle = dotColor; // Use the global dot color variable
            landmarks.forEach(point => {
                const x = point.x * canvasElement.width / pixelRatio;
                const y = point.y * canvasElement.height / pixelRatio;
                canvasCtx.beginPath();
                canvasCtx.arc(x, y, dotSize, 0, 2 * Math.PI);
                canvasCtx.fill();
            });
        }

        canvasCtx.restore();
    }

    drawBlendShapes(videoBlendShapes, results.faceBlendshapes);
    window.requestAnimationFrame(predictWebcam);
}
function drawBlendShapes(el, blendShapes) {
    if (!blendShapes.length) {
        return;
    }

    blendShapes[0].categories.forEach((shape) => {
        const currentTime = Date.now();
      
    });

    // Remove the part that updates the HTML with the list items
    el.innerHTML = ''; // This line clears the list
}
function drawLandmarks(faceLandmarks, pixelRatio) { // Add pixelRatio as a parameter
    canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
    canvasCtx.fillStyle = dotColor;

    faceLandmarks.forEach(landmarks => {
        landmarks.forEach(point => {
            const x = point.x * canvasElement.width / pixelRatio;
            const y = point.y * canvasElement.height / pixelRatio;
            canvasCtx.beginPath();
            canvasCtx.arc(x, y, 10, 0, 2 * Math.PI);
            canvasCtx.fill();
        });
    });
}
function toggleFacialDiagram() {
    const outputCanvas = document.getElementById("output_canvas");
    outputCanvas.style.display = outputCanvas.style.display === "none" ? "block" : "none";
    
    // Update the text content of the "showHideText" element
    const showHideText = document.getElementById("showHideText");
    showHideText.textContent = outputCanvas.style.display === "none" ? "Show Diagram" : "Hide Diagram";
}

// Add a click event listener to the "showHideText" element
const showHideText = document.getElementById("showHideText");
showHideText.addEventListener("click", () => {
    toggleFacialDiagram();
});
</script>

</body>
</html>
